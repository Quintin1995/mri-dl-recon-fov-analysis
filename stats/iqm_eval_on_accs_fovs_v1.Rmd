---
title: "IQM Degradation of Deep Learning Reconstructed Prostate MRI an Evaluation of Lesion Regions."
author: "Quintin van Lohuizen"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Loading necessary libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(tidyr)
```



# Loading Data
```{r loading_data}
data_path <- "C:/Users/Quintin/Documents/phd_local/02_repos/mri-dl-recon-fov-analysis/data/final/iqms_vsharp_r1r3r6_with_ref_regions.csv"
raw_data <- read_csv2(data_path, locale = locale(decimal_mark = "."), col_types = cols(
  pat_id = col_character(),
  acceleration = col_character(),
  roi = col_character(),
  slice = col_double(),
  ssim = col_character(),
  psnr = col_character(),
  rmse = col_character(),
  hfen = col_character()
))
summary(raw_data)
str(raw_data)
```



# Preprocessing Data
```{r preprocessing}

# Convert columns to appropriate types
iqms_data <- raw_data %>%
  mutate(
    pat_id = as.factor(pat_id),
    acceleration = factor(as.numeric(acceleration), levels = c(3.0, 6.0), labels = c("3x", "6x")),
    roi = as.factor(roi),
    slice = as.numeric(slice),
    ssim = as.numeric(ssim),
    psnr = as.numeric(psnr),
    rmse = as.numeric(rmse),  # Ensure rmse is read correctly
    hfen = as.numeric(hfen)
  )

# Check for NA values and handle them if necessary
iqms_data <- iqms_data %>%
  drop_na()

# Summary to check changes
summary(iqms_data)
str(iqms_data)

# Proper rounding for numeric columns (if needed)
iqms_data <- iqms_data %>%
  mutate(
    ssim = round(ssim, 3),
    psnr = round(psnr, 2),
    rmse = round(rmse, 2),
    hfen = round(hfen, 3)
  )

# Display the first few rows of the preprocessed data
head(iqms_data)
```



# Descriptive Statistics
Calculate mean, median, standard deviation, and range for each image quality metric (SSIM, PSNR, RMSE, HFEN) across different acceleration factors and ROIs.
```{r summary_stats}
# Calculate summary statistics for each image quality metric by acceleration and ROI
summary_stats <- iqms_data %>%
  group_by(acceleration, roi) %>%
  summarise(
    mean_ssim = mean(ssim, na.rm = TRUE),
    median_ssim = median(ssim, na.rm = TRUE),
    sd_ssim = sd(ssim, na.rm = TRUE),
    range_ssim = range(ssim, na.rm = TRUE),

    mean_psnr = mean(psnr, na.rm = TRUE),
    median_psnr = median(psnr, na.rm = TRUE),
    sd_psnr = sd(psnr, na.rm = TRUE),
    range_psnr = range(psnr, na.rm = TRUE),

    mean_rmse = mean(rmse, na.rm = TRUE),
    median_rmse = median(rmse, na.rm = TRUE),
    sd_rmse = sd(rmse, na.rm = TRUE),
    range_rmse = range(rmse, na.rm = TRUE),

    mean_hfen = mean(hfen, na.rm = TRUE),
    median_hfen = median(hfen, na.rm = TRUE),
    sd_hfen = sd(hfen, na.rm = TRUE),
    range_hfen = range(hfen, na.rm = TRUE)
  ) %>%
  ungroup()

# Display the summary statistics
summary_stats
```



## Visualization
### Boxplot
Visualize the distribution of each metric across different acceleration factors and ROIs.
```{r boxplot}
# Define the full name map for ROIs
full_name_map <- c(
  'FAV' = 'Full Abdominal View (FAV, ',
  'CPV' = 'Clinical Prostate View (CPV, ',
  'TLV' = 'Targeted Lesion View (TLV, ',
  'PR' =  'Prostate Region (PR, ',
  'FR' =  'Femur Region (FR, ',
  'MR' =  'Muscle Region (MR, ',
  'SFR' = 'Sub. Fat Region (SFR, '
)
print(full_name_map)

# Calculate the number of samples for each ROI
roi_sample_sizes <- iqms_data %>%
  group_by(roi) %>%
  summarise(n = n())

# Ensure the ordering of roi_sample_sizes matches full_name_map
roi_sample_sizes <- roi_sample_sizes %>%
  arrange(factor(roi, levels = names(full_name_map)))

# Update the full name map with sample sizes
full_name_map <- setNames(
  paste(full_name_map, "n=", roi_sample_sizes$n, ")", sep = ""),
  roi_sample_sizes$roi
)

# Reorder the levels for 'roi' factor with the specified order
iqms_data$roi <- factor(iqms_data$roi, levels = c('FAV', 'CPV', 'TLV', 'PR', 'FR', 'MR', 'SFR'))

# Define the metrics and their respective y-axis limits
metrics_limits <- list(
  ssim = c(0.22, 1.0),
  hfen = c(0.1, 1.5),
  psnr = c(9, 43),
  rmse = c(0, 70)
)

# Loop through each metric and create the boxplot with the specified y-axis limits
for (metric in names(metrics_limits)) {
  limits <- metrics_limits[[metric]]
  p <- ggplot(iqms_data, aes(x = acceleration, y = .data[[metric]], fill = roi)) +
    geom_boxplot(outlier.shape = NA) +  # remove outliers from the plot
    theme_minimal() +
    theme(legend.position = "right") +
    labs(title = paste("Boxplot of", toupper(metric)), y = toupper(metric), x = "Acceleration Factor") +
    scale_fill_brewer(palette = "Set1", name = "Region of Interest", labels = full_name_map[levels(iqms_data$roi)]) +
    coord_cartesian(ylim = limits)  # adjust the y-axis limits based on the metric
  
  # Save the plot to file
  ggsave(filename = paste0("boxplot_", metric, ".png"), plot = p, width = 8, height = 6, dpi = 300, bg = "white")
  
  print(p)
}

```


# Statistical Analysis
## Data Preparation
```{r data_prep_stats}
# Filter data for necessary comparisons
fav_tlv_data <- iqms_data %>% filter(roi %in% c("FAV", "TLV"))
cpv_tlv_data <- iqms_data %>% filter(roi %in% c("CPV", "TLV"))
tlv_pr_data  <- iqms_data %>% filter(roi %in% c("TLV", "PR"))

```



## Comparative Analysis
### Wilcoxon Signed-Rank Test - Assumptions
Compare paired observations (e.g., SSIM values between different acceleration factors within the same ROI) to determine if there are statistically significant differences.
Check for symmetry in differences
### Histogram Interpretation

The histograms presented in this analysis illustrate the distribution of differences in SSIM values between various fields of view (FOVs) for paired observations. Specifically, the comparisons made are between the Full Abdominal View (FAV) and Targeted Lesion View (TLV), Clinical Prostate View (CPV) and TLV, and TLV and Prostate Region (PR).

1. **Difference Distribution: FAV vs. TLV**:
   The histogram for FAV vs. TLV shows the frequency of SSIM differences between these views. A symmetrical distribution around zero suggests that the differences are evenly distributed, validating the use of the Wilcoxon Signed-Rank Test for this comparison.

2. **Difference Distribution: CPV vs. TLV**:
   Similarly, the histogram for CPV vs. TLV indicates the differences in SSIM values. The symmetrical nature of this distribution around zero supports the assumption of symmetry required for the Wilcoxon Signed-Rank Test.

3. **Difference Distribution: TLV vs. PR**:
   For the TLV vs. PR comparison, the histogram also shows a balanced distribution around zero. This symmetry suggests that the SSIM differences between these regions are unbiased, making the Wilcoxon Signed-Rank Test suitable for this analysis.

Overall, the symmetry in these histograms confirms that the differences in SSIM values between the paired observations are not biased towards any specific view. Therefore, the Wilcoxon Signed-Rank Test can be reliably used for the comparative analysis of SSIM values across different FOVs.

```{r wilcoxon_assumptions}
# FAV vs. TLV
fav_tlv_diff <- fav_tlv_data %>% 
  group_by(pat_id) %>%
  summarise(diff = ssim[roi == "FAV"] - ssim[roi == "TLV"])
ggplot(fav_tlv_diff, aes(x = diff)) +
  geom_histogram(bins = 30) +
  labs(title = "Difference Distribution: FAV vs. TLV", x = "Difference (FAV - TLV)", y = "Frequency")

# CPV vs. TLV
cpv_tlv_diff <- cpv_tlv_data %>% 
  group_by(pat_id) %>%
  summarise(diff = ssim[roi == "CPV"] - ssim[roi == "TLV"])
ggplot(cpv_tlv_diff, aes(x = diff)) +
  geom_histogram(bins = 30) +
  labs(title = "Difference Distribution: CPV vs. TLV", x = "Difference (CPV - TLV)", y = "Frequency")

# TLV vs. PR
tlv_pr_diff <- tlv_pr_data %>% 
  group_by(pat_id) %>%
  summarise(diff = ssim[roi == "TLV"] - ssim[roi == "PR"])
ggplot(tlv_pr_diff, aes(x = diff)) +
  geom_histogram(bins = 30) +
  labs(title = "Difference Distribution: TLV vs. PR", x = "Difference (TLV - PR)", y = "Frequency")

print("The assumption of symmetry holds.")
```
### Wilcoxon Signed-Rank Test
```{r wilcoxon}
# Perform Wilcoxon Signed-Rank Test for each comparison
# FAV vs. TLV
fav_tlv_test <- fav_tlv_data %>%
  group_by(pat_id) %>%
  summarise(fav = ssim[roi == "FAV"], tlv = ssim[roi == "TLV"]) %>%
  wilcox.test(fav, tlv, paired = TRUE)

# CPV vs. TLV
cpv_tlv_test <- cpv_tlv_data %>%
  group_by(pat_id) %>%
  summarise(cpv = ssim[roi == "CPV"], tlv = ssim[roi == "TLV"]) %>%
  wilcox.test(cpv, tlv, paired = TRUE)

# TLV vs. PR
tlv_pr_test <- tlv_pr_data %>%
  group_by(pat_id) %>%
  summarise(tlv = ssim[roi == "TLV"], pr = ssim[roi == "PR"]) %>%
  wilcox.test(tlv, pr, paired = TRUE)

# Store the p-values in a named list
wilcoxon_results <- list(
  "FAV vs. TLV" = fav_tlv_test$p.value,
  "CPV vs. TLV" = cpv_tlv_test$p.value,
  "TLV vs. PR"  = tlv_pr_test$p.value
)

# Adjust p-values for multiple comparisons using Bonferroni correction
adjusted_p_values <- p.adjust(unlist(wilcoxon_results), method = "bonferroni")
names(adjusted_p_values) <- names(wilcoxon_results)

# Display the results
adjusted_p_values
```
### Kruskal-Wallis Test
Use this non-parametric test to compare multiple groups (e.g., SSIM across different ROIs or acceleration factors) when the data do not follow a normal distribution.
```{r kruskal}
# text
```



## Correlation Analysis
### Spearman's Rank Correlation
Assess the correlation between different image quality metrics (e.g., SSIM vs. PSNR) and between metrics and acceleration factors.
```{r spearman}
# text
```
### Scatter Plots
Visualize relationships between image quality metrics and acceleration factors.
```{r scatter_correlation}
# text
```


## Regression Analysis
### Linear Mixed-Effects Models
Model the relationship between SSIM (and other metrics) and acceleration factors, accounting for random effects due to patient variability and slice index.
```{r linear_mixed_effects_model}
# text
```
### Fixed Effects Models
Evaluate the fixed effects of acceleration, ROI, and their interaction on image quality metrics.
```{r fixed_effects_models}
# TEXT
```
### Random Intercepts Models
Include patient-specific random intercepts to account for repeated measures within patients.
```{r random_intercepts_models}
# TEXT
```



## Analysis of Variance (ANOVA)
### Two-Way ANOVA
Evaluate the interaction effect between acceleration factors and ROIs on image quality metrics.
```{r two_way_anova}
# text
```
### Repeated Measures ANOVA
Use this to account for the within-subject correlation (e.g., multiple slices from the same patient).
```{r repeated_measures_anova}
# text
```



## Post-Hoc Analysis
### Bonferroni Correction
Adjust for multiple comparisons when performing pairwise tests to control for type I error rate.
```{r bonferroni}
# text
```
### Tukey's Honest Significant Difference Test
Use for post-hoc pairwise comparisons following ANOVA.
```{r tukey}
# text
```


---------------------------------------------------------------------------------------------------------------------------------------------------
# Empty block 1 
```{r emtpy_block1}
# text
```

# Empty block 2 
```{r emtpy_block2}
# text
```

# Empty block 3
```{r emtpy_block3}
# text
```